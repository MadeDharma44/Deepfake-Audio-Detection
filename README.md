# Deepfake Audio Detection using Machine Learning and Deep Learning
This project focuses on detecting deepfake audio using audio feature extraction combined with machine learning and deep learning models. The dataset consists of balanced real and fake audio samples. Extracted audio features include MFCC, chroma, spectral contrast, harmonic-to-noise ratio (HNR), and zero crossing rate, which are used to train Random Forest and LSTM classifiers. The best models achieved up to 99% accuracy on training data and over 90% on test data, demonstrating strong performance in distinguishing real from deepfake audio. Visual analyses of waveforms and MFCC spectrograms highlight distinctive characteristics between authentic and synthetic audio. Feature importance evaluation identifies the most influential features for classification. This project provides a solid foundation for building effective and reliable deepfake audio detection systems.
